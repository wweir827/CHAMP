.. CHAMP documentation master file, created by
   sphinx-quickstart on Tue Jul 11 15:50:43 2017.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

=================================
Louvain Parallel Extension
=================================

CHAMP can be used with partitions generated by any community detection algorithm.  One of the most popular \
and fast algorithms is known as Louvain :cite:`Blondel:2008vn` .  We provide an extension to the python package \
developed by Vincent Traag, `louvain_igraph <https://github.com/vtraag/louvain-igraph>`_  :cite:`traag_louvain` to \
run Louvain in parallel, while calculating the coefficients necessary for CHAMP.  Currently, this extension only \
support single-layer network.  The random seed is set within each parallel process to ensure that the results are
stochastic over each run.  In general this is desireable because Louvain uses a greedy optimization schema that \
finds *local* optima.



.. autofunction:: champ.louvain_ext.parallel_louvain


We also have created a convenient class for managing and merging groups of partitions \
called :mod:`champ.louvain_ext.PartitionEnsemble` .  This class stores the partitions in membership vector form \
( i.e. a list of N community assignments), as well as the coefficients for the partitions.  As part of its \
constructor, the PartitionEnsemble applies CHAMP to all of its partitions, and stores the domains of dominance.


.. _`louvain_ext.PartitionEnsemble`:
.. autoclass:: champ.louvain_ext.PartitionEnsemble
    :members: add_partitions,merge_ensemble,apply_CHAMP,plot_modularity_mapping,save,save_graph,open

----------------------------
Partition Ensemble Example
----------------------------
We use igraph to generate a random ER graph, call louvain in parallel, and apply CHAMP to the ensemble.  This example \
took approximately 1 minute to run on 2 cores.
::

    import champ
    import igraph as ig
    import tempfile
    import numpy as np
    import matplotlib.pyplot as plt

    np.random.seed(0)
    test_graph=ig.Graph.Erdos_Renyi(500,p=.05)
    #Create temporary file for calling louvain
    tfile=tempfile.NamedTemporaryFile('wb')
    test_graph.write_graphmlz(tfile.name)

    #non-parallelized wrapper
    ens1=champ.run_louvain(tfile.name,nruns=5,gamma=1)

    #parallelized wrapper
    test_graph2=ig.Graph.Random_Bipartite(n1=100,n2=100,p=.1)
    ens2=champ.parallel_louvain(test_graph2,
                                      numruns=1000,start=0,fin=4,maxpt=4,
                                      numprocesses=2,
                                      progress=True)

    print ("%d of %d domains after application of CHAMP"%(len(ens2.ind2doms),ens2.numparts))
    #plot both of these
    plt.close()
    f,a=plt.subplots(1,3,figsize=(21,7))
    a1,a2,a3=a
    champ.plot_single_layer_modularity_domains(ens2.ind2doms,ax=a1,labels=True)
    champ.plot_similarity_heatmap_single_layer(ens2.partitions,ens2.ind2doms,ax=a2,title=True)

    #PartitionEnsemble has method to plot downsampled summary of all partitions
    #with optmal transitions and number of communities overlayed.

    ens2.plot_modularity_mapping(ax=a3,no_tex=False)
    plt.tight_layout()
    plt.show()




Output\:

|   Run 0 at gamma = 0.000.  Return time: 0.0311
|   Run 200 at gamma = 0.800.  Return time: 0.0508
|   Run 100 at gamma = 0.400.  Return time: 0.0316
|   Run 300 at gamma = 1.200.  Return time: 0.0736
|   Run 400 at gamma = 1.600.  Return time: 0.0889
|   Run 500 at gamma = 2.000.  Return time: 0.1135
|   Run 600 at gamma = 2.400.  Return time: 0.0691
|   Run 700 at gamma = 2.800.  Return time: 0.0743
|   Run 800 at gamma = 3.200.  Return time: 0.0698
|   Run 900 at gamma = 3.600.  Return time: 0.1002
|   10 of 1000 domains after application of CHAMP


.. _`part_ens_exp`:
.. image::  images/part_ens_exp.png
   :width: 90%

-------------------------------------------------------------
Creating and Managing Large Partition Sets
-------------------------------------------------------------

For large sets of partitions on larger networks, loading the entire set of partitions each time you want to \
access the data can take a fair amount of time.  Having to load all of the partitions defeats the purpose of using \
CHAMP to find the optimal subset.  As such we have equiped :mod:`champ.louvain_ext.PartitionEnsemble` \
objects with the ability to write to and access hdf5 files.  Instead of loading the entire set of partitions each \
time, only the coefficients, the domains of dominance, the underlying graph information is loaded. All individual partitions ( or \
all partitions) can be access from file only if needed, as the example below illustrates:

------------------------------------------
Saving and Loading PartitionEnsembles
------------------------------------------
::

    import champ
    import igraph as ig
    import numpy as np

    np.random.seed(0)
    test_graph=ig.Graph.Erdos_Renyi(n=200,p=.1)
    times={}
    run_nums=[100]

    #saving ensemble
    ensemble=champ.parallel_louvain(test_graph,numprocesses=2,numruns=200,start=0,fin=4,maxpt=4,progress=False)
    print "Ensemble 1, Optimal subset is %d of %d partitions"%(len(ensemble.ind2doms),ensemble.numparts)
    ensemble.save("ensemble1.hdf5",hdf5=True)

    #openning created file
    ensemble2=champ.PartitionEnsemble().open("ensemble1.hdf5")
    #partitions is an internal class the handles access
    print ensemble2.partitions
    #When sliced a numpy.array is returned
    print "ensemble2.partitions[38,:10]:\n\t",ensemble2.partitions[38:40,:10]

    #You can still add partitions as normal.  These are automatically
    #added to the hdf5 file
    ensemble2add=champ.parallel_louvain(test_graph,numprocesses=2,numruns=100,start=0,fin=4,maxpt=4,progress=False)
    ensemble2.add_partitions(ensemble2add.get_partition_dictionary())
    print "ensemble 2 has %d of %d partitions dominant"  %(len(ensemble2.ind2doms),ensemble2.numparts)

    #When open is called, the created EnsemblePartition assumes all
    #the state variables of saved EnsemblePartition, including default save file.
    #If save() is called, it will overwrite the old ensemble file
    print "ensemble2 default hdf5 file: ",ensemble2.hdf5_file



Output\:

|   Ensemble 1, Optimal subset is 11 of 200 partitions
|   200 partitions saved on ensemble1.hdf5
|   ensemble2.partitions[38,:10]:
|   	[[1 0 1 0 0 0 0 0 1 1]
|       [1 1 2 0 1 0 2 1 2 1]]
|   ensemble 2 has 12 of 300 partitions dominant

You can see with the above example that CHAMP is reapplied everytime new partitions are added to the \
 :mod:`louvain_ext.PartitionEnsemble` instance.

------------------------------------------------
Merging PartitionEnsembles
------------------------------------------------

::

    import champ
    import igraph as ig
    import numpy as np

    np.random.seed(0)
    test_graph=ig.Graph.Erdos_Renyi(n=200,p=.1)
    times={}
    run_nums=[100]

    ensemble=champ.parallel_louvain(test_graph,numprocesses=2,numruns=200,start=0,fin=4,maxpt=4,progress=False)
    print "Ensemble 1, Optimal subset is %d of %d partitions"%(len(ensemble.ind2doms),ensemble.numparts)
    ensemble.save("ensemble1.hdf5",hdf5=True)

    ensemble2=champ.parallel_louvain(test_graph,numprocesses=2,numruns=200,start=0,fin=4,maxpt=4,progress=False)
    print "Ensemble 2, Optimal subset is %d of %d partitions"%(len(ensemble2.ind2doms),ensemble2.numparts)
    ensemble2.save("ensemble2.hdf5",hdf5=True)

    #Esembles can be merged as follows:

    #Create new PartitionEnsemble from scratch
    ensemble3=ensemble.merge_ensemble(ensemble2,new=True)
    print "Ensemble 3, Optimal subset is %d of %d partitions"%(len(ensemble3.ind2doms),ensemble3.numparts)

    #Use largest of the 2 PartitionEnsembles being merged  and modify
    ensemble4=ensemble.merge_ensemble(ensemble3,new=False)
    print "Ensemble 4, Optimal subset is %d of %d partitions"%(len(ensemble4.ind2doms),ensemble4.numparts)
    print "ensemble4 is ensemble3: ",ensemble4 is ensemble3

Output\:

|   Ensemble 1, Optimal subset is 13 of 200 partitions
|   Ensemble 2, Optimal subset is 15 of 200 partitions
|   Ensemble 3, Optimal subset is 15 of 400 partitions
|   Ensemble 4, Optimal subset is 15 of 600 partitions
|   ensemble4 is ensemble3:  True


-------------------------------------------------------
Improvement with HDF5 saving and loading
-------------------------------------------------------
The following example gives a sense of when it is beneficial to save as HDF5 and general runtimes for parallelized\
Louvain.  We also found that the overhead is dependent on the size of the graph as well, so that for larger graphs \
with a lower number of partitions, the read/write time on HDF5 can be greater.

::

    import champ
    import matplotlib.pyplot as plt
    import seaborn as sbn
    import numpy as np
    import pandas as pd
    import igraph as ig
    from time import time
    import gzip
    import cPickle as pickle
    np.random.seed(0)
    test_graph=ig.Graph.Erdos_Renyi(n=1000,p=.1)

    times={}
    run_nums=[100,1000,2000,3000,10000]

    for nrun in run_nums :
        rtimes=[]
        t=time()
        ens=champ.parallel_louvain(test_graph,numprocesses=10,numruns=nrun,start=0,fin=4,maxpt=4,progress=False)
        ens.name='name'
        rtimes.append(time()-t)

        #normal save (gzip)
        print "CHAMP running time %d runs: %.3f" %(nrun,rtimes[-1])
        t=time()
        ens.save()
        rtimes.append(time()-t)
        t=time()

        #normal open
        t=time()
        newens=champ.PartitionEnsemble().open("name_PartEnsemble_%d.gz"%nrun)
        rtimes.append(time()-t)
        t=time()

        #save with h5py
        t=time()
        ens.save(hdf5=True)
        rtimes.append(time()-t)
        t=time()

        #open with hdf5 format
        t=time()
        newes=champ.PartitionEnsemble().open("name_PartEnsemble_%d.hdf5"%nrun)
        rtimes.append(time()-t)
        times[nrun]=rtimes

    tab=pd.DataFrame(times,columns=run_nums,index=['runtime','save','load','hdf5save','hdf5load'])
    colors=sbn.color_palette('Set1',n_colors=tab.shape[0])
    plt.close()
    f,(a1,a2)=plt.subplots(2,1)
    for i,ind in enumerate(tab.index.values):
        if ind=='runtime':
            a1.plot(tab.columns,tab.loc[ind,:],label=ind,color=colors[i])
        else:
            a2.plot(tab.columns,tab.loc[ind,:],label=ind,color=colors[i])

    a1.set_xlabel("#partitions")
    a1.ylabel("seconds")
    a2.set_xlabel("#partitions")
    a2.ylabel("seconds")

    a1.set_title("Comparison of Save and Load Times")
    a1.set_title("Runtimes on random ER-graph G(N=1000,p=.1)")
    a1.legend()
    a2.legend()
    plt.show()

References
___________

.. bibliography:: biblio.bib
    :style: plain
    :filter: docname in docnames




* :ref:`genindex`
* :ref:`search`

